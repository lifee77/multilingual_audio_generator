{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Audio Classification: Speaker & Language\n","\n","This notebook does the following:\n","1. Use a single **metadata CSV** to label both **speaker** and **language**.\n","2. Extract **MFCC features** from each audio file.\n","3. Perform **binary classification** separately for:\n","   - **Speaker** (Jeevan vs. Not_Jeevan)\n","   - **Language** (English vs. Not_English)\n","4. Use **k-Fold Cross-Validation** to evaluate performance (accuracy, precision, recall, F1) and generate confusion matrices."]},{"cell_type":"code","execution_count":6,"id":"14b40732","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: librosa in /opt/anaconda3/lib/python3.12/site-packages (0.10.2.post1)\n","Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (1.4.2)\n","Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (2.2.2)\n","Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n","Requirement already satisfied: audioread>=2.1.9 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (3.0.1)\n","Requirement already satisfied: scipy>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (1.13.1)\n","Requirement already satisfied: joblib>=0.14 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (1.4.2)\n","Requirement already satisfied: decorator>=4.3.0 in /Users/jeevanbhatta/.local/lib/python3.12/site-packages (from librosa) (5.1.1)\n","Requirement already satisfied: numba>=0.51.0 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (0.59.1)\n","Requirement already satisfied: soundfile>=0.12.1 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (0.13.1)\n","Requirement already satisfied: pooch>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (1.8.2)\n","Requirement already satisfied: soxr>=0.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (0.5.0.post1)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (4.11.0)\n","Requirement already satisfied: lazy-loader>=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from librosa) (1.0.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn) (2.2.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jeevanbhatta/.local/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n","Requirement already satisfied: packaging in /Users/jeevanbhatta/.local/lib/python3.12/site-packages (from lazy-loader>=0.1->librosa) (24.2)\n","Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/anaconda3/lib/python3.12/site-packages (from numba>=0.51.0->librosa) (0.42.0)\n","Requirement already satisfied: platformdirs>=2.5.0 in /Users/jeevanbhatta/.local/lib/python3.12/site-packages (from pooch>=1.1->librosa) (4.3.6)\n","Requirement already satisfied: requests>=2.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from pooch>=1.1->librosa) (2.32.2)\n","Requirement already satisfied: six>=1.5 in /Users/jeevanbhatta/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: cffi>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n","Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n"]}],"source":["#Installing All Required Libraries\n","!pip install librosa scikit-learn pandas numpy"]},{"cell_type":"code","execution_count":8,"id":"cda41d9e","metadata":{},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'numpy'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#Importing ALl libraries\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mos\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mnumpy\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mpandas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mas\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mlibrosa\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"]}],"source":["#Importing ALl libraries\n","import os\n","import numpy as np\n","import pandas as pd\n","import librosa\n","from sklearn.model_selection import StratifiedKFold, cross_val_predict\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report, confusion_matrix"]},{"cell_type":"code","execution_count":9,"metadata":{"collapsed":false},"outputs":[],"source":["\n","def extract_features(file_path, sr=16000, n_mfcc=13):\n","    \"\"\"\n","    Loads the audio file, extracts MFCC features, and returns the averaged MFCCs.\n","    \"\"\"\n","    y, sr = librosa.load(file_path, sr=sr)\n","    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n","    mfcc_mean = np.mean(mfcc, axis=1)\n","    return mfcc_mean\n","\n","def build_dataset(metadata_csv, audio_dir):\n","    \"\"\"\n","    Reads metadata from a CSV that has at least 3 columns:\n","        - filename\n","        - speaker_label (e.g., \"Jeevan\" or \"Not_Jeevan\")\n","        - language_label (e.g., \"English\" or \"Not_English\")\n","    \"\"\"\n","    df = pd.read_csv(metadata_csv)\n","    X, y_speaker, y_language = [], [], []\n","    for _, row in df.iterrows():\n","        file_path = os.path.join(audio_dir, row['filename'])\n","        X.append(extract_features(file_path))\n","        y_speaker.append(1 if row['speaker_label'].lower() == 'jeevan' else 0)\n","        y_language.append(1 if row['language_label'].lower() == 'english' else 0)\n","    return np.array(X), np.array(y_speaker), np.array(y_language)\n","\n","def evaluate_classifier(X, y, n_splits=5):\n","    \"\"\"\n","    Performs k-Fold cross-validation, returns classification metrics and a confusion matrix.\n","    \"\"\"\n","    clf = SVC(kernel='linear', probability=True, random_state=42)\n","    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n","    y_pred = cross_val_predict(clf, X, y, cv=skf)\n","    return classification_report(y, y_pred, target_names=[\"Class 0\", \"Class 1\"]), confusion_matrix(y, y_pred)"]},{"cell_type":"code","execution_count":10,"id":"cba31681","metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'pd' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb Cell 5\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m audio_directory \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdata/audio_files\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Build dataset\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X, y_speaker, y_language \u001b[39m=\u001b[39m build_dataset(metadata_csv_path, audio_directory)\n","\u001b[1;32m/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W6sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mbuild_dataset\u001b[39m(metadata_csv, audio_dir):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m    Reads metadata from a CSV that has at least 3 columns:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m        - filename\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m        - speaker_label (e.g., \"Jeevan\" or \"Not_Jeevan\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m        - language_label (e.g., \"English\" or \"Not_English\")\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(metadata_csv)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     X, y_speaker, y_language \u001b[39m=\u001b[39m [], [], []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mfor\u001b[39;00m _, row \u001b[39min\u001b[39;00m df\u001b[39m.\u001b[39miterrows():\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}],"source":["# Paths to metadata CSV and audio files folder\n","metadata_csv_path = \"data/metadata.csv\"\n","audio_directory = \"data/audio_files\"\n","\n","# Build dataset\n","X, y_speaker, y_language = build_dataset(metadata_csv_path, audio_directory)"]},{"cell_type":"code","execution_count":11,"id":"33084131","metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'X' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32m/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Speaker Classification\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m speaker_report, speaker_cm \u001b[39m=\u001b[39m evaluate_classifier(X, y_speaker, n_splits\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m=== Speaker Classification (Jeevan vs. Not_Jeevan) ===\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jeevanbhatta/Minerva/Machine-Learning-CS156/voice-classification/audio_classification.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mClassification Report:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, speaker_report)\n","\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"]}],"source":["# Speaker Classification\n","speaker_report, speaker_cm = evaluate_classifier(X, y_speaker, n_splits=5)\n","print(\"=== Speaker Classification (Jeevan vs. Not_Jeevan) ===\")\n","print(\"Classification Report:\\n\", speaker_report)\n","print(\"Confusion Matrix:\\n\", speaker_cm)\n"]},{"cell_type":"code","execution_count":null,"id":"417f1125","metadata":{},"outputs":[],"source":["# Language Classification\n","language_report, language_cm = evaluate_classifier(X, y_language, n_splits=5)\n","print(\"\\n=== Language Classification (English vs. Not_English) ===\")\n","print(\"Classification Report:\\n\", language_report)\n","print(\"Confusion Matrix:\\n\", language_cm)\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"},"name":"AudioClassificationNotebook"},"nbformat":4,"nbformat_minor":5}
